{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/autofs/homes/005/fd881/repos/MedImaging-ModelDriftMonitoring/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "#import click\n",
    "#import plotnine\n",
    "from pycrumbs import tracked\n",
    "import multiprocessing\n",
    "\n",
    "from src.model_drift.data import mgb_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from src.model_drift import helpers, mgb_locations\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.linalg import det, inv\n",
    "import scipy\n",
    "from datetime import timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_date(df, splits, col=None):\n",
    "    splits = pd.to_datetime(splits).sort_values()\n",
    "\n",
    "    rem = df\n",
    "\n",
    "    for split in splits:\n",
    "        if col is None:\n",
    "            curr, rem = rem[rem.index < split], rem[rem.index >= split]\n",
    "        else:\n",
    "            curr, rem = rem[rem[col] < split], rem[rem[col] >= split]\n",
    "        yield curr\n",
    "    yield rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_index(row: pd.Series):\n",
    "    return f\"{row.PatientID}_{row.AccessionNumber}_{row.SOPInstanceUID}\"\n",
    "\n",
    "meta_df = pd.read_csv(\n",
    "    mgb_locations.dicom_inventory_csv,\n",
    "    index_col=0,\n",
    ")\n",
    "meta_df.drop(columns=[\"StudyDate\"], inplace=True)  # anonymized dates\n",
    "labels_df = pd.read_csv(\n",
    "    mgb_locations.labels_csv,\n",
    "    index_col=0,\n",
    ")  # need real dates from this file\n",
    "meta_df = meta_df.merge(\n",
    "    labels_df,\n",
    "    how=\"left\",\n",
    "    on=(\"StudyInstanceUID\", \"PatientID\", \"AccessionNumber\"),\n",
    ")\n",
    "\n",
    "# Some metadata is from the RIS and is in the reports CSV\n",
    "reports = pd.read_csv(mgb_locations.reports_csv, dtype=str)\n",
    "reports = reports[\n",
    "    [\n",
    "        \"Accession Number\",\n",
    "        \"Point of Care\",\n",
    "        \"Patient Sex\",\n",
    "        \"Patient Age\",\n",
    "        \"Is Stat\",\n",
    "        \"Exam Code\",\n",
    "    ]\n",
    "].copy()\n",
    "crosswalk = pd.read_csv(mgb_locations.crosswalk_csv, dtype={\"ANON_AccNumber\": int})\n",
    "crosswalk = crosswalk[[\"ANON_AccNumber\", \"ORIG_AccNumber\"]]\n",
    "# meta_df.assign(AccessionNumber=lambda x: x.AccessionNumber.str.lstrip(\"0\"))\n",
    "\n",
    "meta_df = meta_df.merge(\n",
    "    crosswalk,\n",
    "    how=\"left\",\n",
    "    left_on=\"AccessionNumber\",\n",
    "    right_on=\"ANON_AccNumber\",\n",
    "    validate=\"many_to_one\",\n",
    ")\n",
    "meta_df = meta_df.merge(\n",
    "    reports,\n",
    "    how=\"left\",\n",
    "    left_on=\"ORIG_AccNumber\",\n",
    "    right_on=\"Accession Number\",\n",
    "    validate=\"many_to_one\",\n",
    ")\n",
    "\n",
    "meta_df[\"StudyDate\"] = pd.to_datetime(meta_df[\"StudyDate\"], format='%m/%d/%Y')\n",
    "meta_df[\"index\"] = meta_df.apply(make_index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to 512 for using the resnet features\n",
    "num_feat = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae_pred_file = '/autofs/cluster/qtim/projects/xray_drift/models/mgb/resnet_features/preds.jsonl' #resnet_features\n",
    "vae_pred_file = '/autofs/cluster/qtim/projects/xray_drift/inferences/mgb_with_chexpert_model_vae_take2/preds.jsonl' #vae_features\n",
    "\n",
    "vae_df = helpers.jsonl_files2dataframe([vae_pred_file], desc=\"reading VAE results\", refresh_rate=.1)\n",
    "vae_df = pd.concat(\n",
    "    [\n",
    "        vae_df,\n",
    "        pd.DataFrame(vae_df['mu'].values.tolist(), columns=[f\"mu.{c:0>3}\" for c in range(num_feat)]) #512\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "vae_df.drop_duplicates(subset=\"index\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = meta_df.merge(vae_df, on=\"index\", how=\"left\")\n",
    "train_df, val_df, test_df = split_on_date(\n",
    "        merged_df,\n",
    "        [mgb_data.TRAIN_DATE_END, mgb_data.VAL_DATE_END],\n",
    "        col=\"StudyDate\",\n",
    "    )\n",
    "\n",
    "merged_df.set_index(\"StudyDate\", inplace=True)\n",
    "merged_df_use = merged_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_mvn(to, fr):\n",
    "    \"\"\"Calculate `KL(to||fr)`, where `to` and `fr` are pairs of means and covariance matrices\"\"\"\n",
    "    m_to, S_to = to\n",
    "    m_fr, S_fr = fr\n",
    "    \n",
    "    S_to += np.eye(S_to.shape[0]) * 1e-6\n",
    "    S_fr += np.eye(S_fr.shape[0]) * 1e-6\n",
    "\n",
    "    d = m_fr - m_to\n",
    "    \n",
    "    c, lower = scipy.linalg.cho_factor(S_fr)\n",
    "    def solve(B):\n",
    "        return scipy.linalg.cho_solve((c, lower), B)\n",
    "    \n",
    "    def logdet(S):\n",
    "        return np.linalg.slogdet(S)[1]\n",
    "\n",
    "    term1 = np.trace(solve(S_to))\n",
    "    term2 = logdet(S_fr) - logdet(S_to)\n",
    "    term3 = d.T @ solve(d)\n",
    "    return (term1 + term2 + term3 - len(d))/2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_rows = val_df['mu'].apply(lambda x: isinstance(x, list))\n",
    "val_df = val_df[list_rows]\n",
    "list_rows = merged_df_use['mu'].apply(lambda x: isinstance(x, list))\n",
    "merged_df_use = merged_df_use[list_rows]\n",
    "\n",
    "# Define the reference set and fit the reference Gaussian\n",
    "#reference_set = np.array(vae_df_use['mu'].iloc[:5000].tolist())\n",
    "reference_set = np.array(val_df['mu'].tolist())\n",
    "reference_set = reference_set.reshape((len(val_df), num_feat)) #512\n",
    "reference_set = np.nan_to_num(reference_set, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "mean_vector_ref = np.mean(reference_set, axis=0)\n",
    "covariance_matrix_ref = np.cov(reference_set, rowvar=False)\n",
    "\n",
    "# Function to generate windows\n",
    "def generate_windows(start_date, end_date, window_size_days=30, stride_days=1):\n",
    "    current_start = start_date\n",
    "    while current_start + timedelta(days=window_size_days) <= end_date:\n",
    "        current_end = current_start + timedelta(days=window_size_days)\n",
    "        yield current_start, current_end\n",
    "        current_start += timedelta(days=stride_days)\n",
    "\n",
    "# Convert index to datetime if not already\n",
    "merged_df_use.index = pd.to_datetime(merged_df_use.index)\n",
    "\n",
    "# Get the overall start and end dates\n",
    "start_date = merged_df_use.index.min()\n",
    "end_date = merged_df_use.index.max()\n",
    "\n",
    "kl_results = []\n",
    "\n",
    "for window_start, window_end in tqdm(generate_windows(start_date, end_date)):\n",
    "    # Select data for the current window\n",
    "    window_data = merged_df_use[(merged_df_use.index >= window_start) & (merged_df_use.index < window_end)]\n",
    "\n",
    "    # Check if there are enough samples, if not, continue to next window\n",
    "    if len(window_data) < 1:\n",
    "        continue\n",
    "\n",
    "    # Reshape the data\n",
    "    comparison_set = np.array(window_data['mu'].tolist())\n",
    "    comparison_set = comparison_set.reshape((len(window_data), num_feat)) #512\n",
    "    comparison_set = np.nan_to_num(comparison_set, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Fit a Gaussian to the comparison set\n",
    "    mean_vector_comp = np.mean(comparison_set, axis=0)\n",
    "    covariance_matrix_comp = np.cov(comparison_set, rowvar=False)\n",
    "\n",
    "    # Compute KL divergence\n",
    "    kl_divergence = kl_mvn((mean_vector_ref, covariance_matrix_ref), (mean_vector_comp, covariance_matrix_comp))\n",
    "\n",
    "    # Store the result with the start date\n",
    "    kl_results.append({'start_date': window_start, 'kl_divergence': kl_divergence})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "kl_df = pd.DataFrame(kl_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(kl_df['start_date'], kl_df['kl_divergence'])\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())  \n",
    "plt.gcf().autofmt_xdate()  \n",
    "\n",
    "plt.title(\"KL Divergence Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"KL Divergence\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rows = val_df['mu'].apply(lambda x: isinstance(x, list))\n",
    "val_df = val_df[list_rows]\n",
    "list_rows = merged_df_use['mu'].apply(lambda x: isinstance(x, list))\n",
    "merged_df_use = merged_df_use[list_rows]\n",
    "# Step 1: Define the reference set and fit the reference Gaussian\n",
    "#reference_set = np.array(vae_df_use['mu'].iloc[:5000].tolist())\n",
    "reference_set = np.array(val_df['mu'].tolist())\n",
    "reference_set = reference_set.reshape((len(val_df), 512))\n",
    "reference_set = np.nan_to_num(reference_set, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "mean_vector_ref = np.mean(reference_set, axis=0)\n",
    "covariance_matrix_ref = np.cov(reference_set, rowvar=False)\n",
    "\n",
    "# Step 2: Apply sliding window approach\n",
    "window_size = 1000\n",
    "stride = 500  # Stride of 1000 for no overlap\n",
    "num_windows = (len(vae_df_use) - window_size) // stride + 1\n",
    "kl_list = []\n",
    "\n",
    "for i in tqdm(range(num_windows)):\n",
    "    window_start = i * stride\n",
    "    comparison_set = np.array(merged_df_use['mu'].iloc[window_start:window_start + window_size].tolist())\n",
    "    comparison_set = comparison_set.reshape((1000, 512))\n",
    "    comparison_set = np.nan_to_num(comparison_set, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Fit a Gaussian to the comparison set\n",
    "    mean_vector_comp = np.mean(comparison_set, axis=0)\n",
    "    covariance_matrix_comp = np.cov(comparison_set, rowvar=False)\n",
    "\n",
    "    # Compute KL divergence\n",
    "    kl_divergence = kl_mvn((mean_vector_ref, covariance_matrix_ref), (mean_vector_comp, covariance_matrix_comp))\n",
    " \n",
    "    # Process the KL divergence result as needed\n",
    "    kl_list.append(kl_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(kl_list)  # or plt.bar(range(len(kl_values)), kl_values) for a bar plot\n",
    "plt.title(\"KL Divergence over Different Windows\")\n",
    "plt.xlabel(\"Window Number\")\n",
    "plt.ylabel(\"KL Divergence\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xray-drift-nlp",
   "language": "python",
   "name": "xray-drift-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
